{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e04a0405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: '#The': Expected package name at the start of dependency specifier\n",
      "    #The\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk #The percentage makes sure that the jupiter note book command is installed in the same enviournment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38239e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Hello Welocome to my python's notebook to teach me about NLP.\n",
    "This will teach me techniques on NLP, like tokenization!\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "639b4284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rohan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69998627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization 1) Paragraph to sentences\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "documents = sent_tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca83ddce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"H e l l o   W e l o c o m e   t o   m y   p y t h o n' s   n o t e b o o k   t o   t e a c h   m e   a b o u t   N L P . \\n T h i s   w i l l   t e a c h   m e   t e c h n i q u e s   o n   N L P,   l i k e   t o k e n i z a t i o n!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization 2) pragraph/sentence to words \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(corpus) #This makes every word has been split individually\n",
    "\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(corpus) #This makes every word has been split individually, the difference being that it takes care of the 's and splits them as well, individually \n",
    "\n",
    "from nltk.tokenize import TreebankWordDetokenizer\n",
    "tokenizer=TreebankWordDetokenizer()\n",
    "tokenizer.tokenize(corpus) #what this does is that fullstop is not considered as a new word.\n",
    "\n",
    "\n",
    "#Mainly we use word_tokenize and sent_tokenize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
